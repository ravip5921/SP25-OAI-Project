{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "20edb164d0c8494698370573506b50d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddd3409e448741e89a18c62f16c44e34",
              "IPY_MODEL_83e41086c8da4acebecb9cdff196f1da",
              "IPY_MODEL_6e8b64b949da4ed4aae8bd918aefaa2c"
            ],
            "layout": "IPY_MODEL_7596afeb8de749bdb76ccb6602ccf398"
          }
        },
        "ddd3409e448741e89a18c62f16c44e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ed58d33db042a8abc368a1da0e01f8",
            "placeholder": "​",
            "style": "IPY_MODEL_3e1f5a868d2d431f9623689d8c20bb2b",
            "value": "config.json: 100%"
          }
        },
        "83e41086c8da4acebecb9cdff196f1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58b6e412525b458a81966d68dd569f9d",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ff38cdd41984a07907b592e618bfcaa",
            "value": 313
          }
        },
        "6e8b64b949da4ed4aae8bd918aefaa2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f700c01f57ef40d88b375ccc06f32748",
            "placeholder": "​",
            "style": "IPY_MODEL_a40f50712d9e477e97e34a24fd37fc6c",
            "value": " 313/313 [00:00&lt;00:00, 22.3kB/s]"
          }
        },
        "7596afeb8de749bdb76ccb6602ccf398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ed58d33db042a8abc368a1da0e01f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1f5a868d2d431f9623689d8c20bb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58b6e412525b458a81966d68dd569f9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ff38cdd41984a07907b592e618bfcaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f700c01f57ef40d88b375ccc06f32748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40f50712d9e477e97e34a24fd37fc6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "753837f1d39a4328ab0e61ff51a204b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_369cb97929114f7ca7f734a89d997232",
              "IPY_MODEL_5f7a5e382a694ff6a42ae14756b7060c",
              "IPY_MODEL_0e07ac6eb3df4c5f8c2fd32539ebc5ba"
            ],
            "layout": "IPY_MODEL_91ce352423f947dd8f09150b58325ec3"
          }
        },
        "369cb97929114f7ca7f734a89d997232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bf2b57826294c0683637a0590bf3159",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e3c29f602749a19893d49b4b02f6d9",
            "value": "vocab.txt: 100%"
          }
        },
        "5f7a5e382a694ff6a42ae14756b7060c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d13c0725f8b44f64ad5534d5fc86354e",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c85c98bf72be4ea190c799e2c89aaef7",
            "value": 213450
          }
        },
        "0e07ac6eb3df4c5f8c2fd32539ebc5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752f25d5581a4cb98817f654980fb4e6",
            "placeholder": "​",
            "style": "IPY_MODEL_3bf44ca6eafe41f39f0630c39e7deafb",
            "value": " 213k/213k [00:00&lt;00:00, 1.74MB/s]"
          }
        },
        "91ce352423f947dd8f09150b58325ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bf2b57826294c0683637a0590bf3159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e3c29f602749a19893d49b4b02f6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d13c0725f8b44f64ad5534d5fc86354e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c85c98bf72be4ea190c799e2c89aaef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "752f25d5581a4cb98817f654980fb4e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf44ca6eafe41f39f0630c39e7deafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwyozytqZwt3",
        "outputId": "5db2f2fc-0fcb-42f2-dcc3-a157fba240bf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzip uploaded file\n",
        "with zipfile.ZipFile(\"iob_output.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"iob_data\")\n",
        "\n",
        "# Check file names\n",
        "file_names = os.listdir(\"iob_data\")\n",
        "print(\"Number of files:\", len(file_names))\n",
        "print(\"Example file:\", file_names[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCtGnqHzaLAN",
        "outputId": "42ce3502-1598-4499-fad8-57b96c55cd18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files: 97\n",
            "Example file: 16579849.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_iob_data_from_folder(folder_path):\n",
        "    all_sentences = []\n",
        "    for fname in os.listdir(folder_path):\n",
        "        if fname.endswith(\".txt\"):\n",
        "            with open(os.path.join(folder_path, fname), \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "                all_sentences.extend(data)  # each file has many sentences\n",
        "    return all_sentences\n",
        "\n",
        "sentences = load_iob_data_from_folder(\"iob_data\")\n",
        "print(\"Total sentences loaded:\", len(sentences))\n",
        "print(\"Example:\", sentences[0][:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_62axHzaQ71",
        "outputId": "af4d0a91-722b-46e6-d3c4-42ba300afde4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences loaded: 28559\n",
            "Example: [['Production', 'O'], ['and', 'O'], ['characterization', 'O'], ['of', 'O'], ['murine', 'O']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split sentences into train and test (80% train, 20% test)\n",
        "train_sentences, test_sentences = train_test_split(sentences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further split train_sentences into train and validation (80% train, 20% validation)\n",
        "train_sentences, val_sentences = train_test_split(train_sentences, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {len(train_sentences)}\")\n",
        "print(f\"Validation set size: {len(val_sentences)}\")\n",
        "print(f\"Test set size: {len(test_sentences)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR1cIU29xpfo",
        "outputId": "2cb4cbc2-c88d-4d5b-ae3b-0292007d7707"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 18277\n",
            "Validation set size: 4570\n",
            "Test set size: 5712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "def tokenize_and_chunk(sentences, tokenizer, max_len=512, stride=256, pad_label=\"PAD\"):\n",
        "    tokenized_inputs = []\n",
        "    aligned_labels = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words, labels = zip(*sentence)\n",
        "        tokens = []\n",
        "        token_labels = []\n",
        "\n",
        "        for word, label in zip(words, labels):\n",
        "            word_pieces = tokenizer.tokenize(word)\n",
        "            tokens.extend(word_pieces)\n",
        "            token_labels.extend([label] + [pad_label] * (len(word_pieces) - 1))\n",
        "\n",
        "        # Chunking logic\n",
        "        start = 0\n",
        "        while start < len(tokens):\n",
        "            end = min(start + max_len, len(tokens))\n",
        "            chunk_tokens = tokens[start:end]\n",
        "            chunk_labels = token_labels[start:end]\n",
        "\n",
        "            # Convert to IDs\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(chunk_tokens)\n",
        "\n",
        "            tokenized_inputs.append(input_ids)\n",
        "            aligned_labels.append(chunk_labels)\n",
        "\n",
        "            if end == len(tokens):\n",
        "                break\n",
        "            start += stride\n",
        "\n",
        "    return tokenized_inputs, aligned_labels\n",
        "\n",
        "# Now, tokenize and chunk for each of the splits\n",
        "train_token_ids, train_label_ids = tokenize_and_chunk(train_sentences, tokenizer)\n",
        "val_token_ids, val_label_ids = tokenize_and_chunk(val_sentences, tokenizer)\n",
        "test_token_ids, test_label_ids = tokenize_and_chunk(test_sentences, tokenizer)\n",
        "\n",
        "# Optional: Check the first example from each set to confirm\n",
        "print(\"Example train token IDs:\", train_token_ids[0][:10])\n",
        "print(\"Corresponding train labels:\", train_label_ids[0][:10])\n",
        "\n",
        "print(\"Example validation token IDs:\", val_token_ids[0][:10])\n",
        "print(\"Corresponding validation labels:\", val_label_ids[0][:10])\n",
        "\n",
        "print(\"Example test token IDs:\", test_token_ids[0][:10])\n",
        "print(\"Corresponding test labels:\", test_label_ids[0][:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "20edb164d0c8494698370573506b50d3",
            "ddd3409e448741e89a18c62f16c44e34",
            "83e41086c8da4acebecb9cdff196f1da",
            "6e8b64b949da4ed4aae8bd918aefaa2c",
            "7596afeb8de749bdb76ccb6602ccf398",
            "77ed58d33db042a8abc368a1da0e01f8",
            "3e1f5a868d2d431f9623689d8c20bb2b",
            "58b6e412525b458a81966d68dd569f9d",
            "3ff38cdd41984a07907b592e618bfcaa",
            "f700c01f57ef40d88b375ccc06f32748",
            "a40f50712d9e477e97e34a24fd37fc6c",
            "753837f1d39a4328ab0e61ff51a204b1",
            "369cb97929114f7ca7f734a89d997232",
            "5f7a5e382a694ff6a42ae14756b7060c",
            "0e07ac6eb3df4c5f8c2fd32539ebc5ba",
            "91ce352423f947dd8f09150b58325ec3",
            "4bf2b57826294c0683637a0590bf3159",
            "e3e3c29f602749a19893d49b4b02f6d9",
            "d13c0725f8b44f64ad5534d5fc86354e",
            "c85c98bf72be4ea190c799e2c89aaef7",
            "752f25d5581a4cb98817f654980fb4e6",
            "3bf44ca6eafe41f39f0630c39e7deafb"
          ]
        },
        "id": "xnbNBCObaRnD",
        "outputId": "97984c8a-4eec-4824-b789-760094b074d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20edb164d0c8494698370573506b50d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "753837f1d39a4328ab0e61ff51a204b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example train token IDs: [1143, 1306, 1884, 118, 10187, 1104, 1103, 2025, 1105, 6842]\n",
            "Corresponding train labels: ['O', 'PAD', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Example validation token IDs: [174, 1477, 2087, 1475, 1108, 1145, 11168, 1107, 1241, 4272]\n",
            "Corresponding validation labels: ['O', 'PAD', 'PAD', 'PAD', 'O', 'O', 'O', 'O', 'O', 'B']\n",
            "Example test token IDs: [9279, 1167, 27021, 1108, 1562, 1107, 1103, 9455, 7301, 9084]\n",
            "Corresponding test labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PAD', 'PAD']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n"
      ],
      "metadata": {
        "id": "3xQ7fJrcaVEM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Function to convert inputs and labels to tensors and pad them\n",
        "def prepare_data(token_ids, label_ids, tokenizer):\n",
        "    # 1. Convert input and label sequences to tensors\n",
        "    input_id_tensors = [torch.tensor(seq) for seq in token_ids]\n",
        "    label_map = {\"O\": 0, \"B\": 1, \"I\": 2}\n",
        "\n",
        "    label_id_tensors = [\n",
        "        torch.tensor([\n",
        "            label_map[lbl] if lbl in label_map else -100  # <- safely handles 'PAD' or others\n",
        "            for lbl in labels\n",
        "        ])\n",
        "        for labels in label_ids\n",
        "    ]\n",
        "\n",
        "    # 2. Pad sequences\n",
        "    padded_inputs = pad_sequence(input_id_tensors, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    padded_labels = pad_sequence(label_id_tensors, batch_first=True, padding_value=-100)  # -100 ignored in loss\n",
        "\n",
        "    # 3. Create attention masks\n",
        "    attention_masks = (padded_inputs != tokenizer.pad_token_id).long()\n",
        "\n",
        "    return padded_inputs, padded_labels, attention_masks\n",
        "\n",
        "# Prepare the data for each split\n",
        "train_padded_inputs, train_padded_labels, train_attention_masks = prepare_data(train_token_ids, train_label_ids, tokenizer)\n",
        "val_padded_inputs, val_padded_labels, val_attention_masks = prepare_data(val_token_ids, val_label_ids, tokenizer)\n",
        "test_padded_inputs, test_padded_labels, test_attention_masks = prepare_data(test_token_ids, test_label_ids, tokenizer)\n",
        "\n",
        "# Check shapes for each split\n",
        "print(\"Training set shapes:\")\n",
        "print(\"Padded inputs shape:\", train_padded_inputs.shape)\n",
        "print(\"Padded labels shape:\", train_padded_labels.shape)\n",
        "print(\"Attention masks shape:\", train_attention_masks.shape)\n",
        "\n",
        "print(\"\\nValidation set shapes:\")\n",
        "print(\"Padded inputs shape:\", val_padded_inputs.shape)\n",
        "print(\"Padded labels shape:\", val_padded_labels.shape)\n",
        "print(\"Attention masks shape:\", val_attention_masks.shape)\n",
        "\n",
        "print(\"\\nTest set shapes:\")\n",
        "print(\"Padded inputs shape:\", test_padded_inputs.shape)\n",
        "print(\"Padded labels shape:\", test_padded_labels.shape)\n",
        "print(\"Attention masks shape:\", test_attention_masks.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5QCulnea7_J",
        "outputId": "408b8d74-ee75-4b76-899f-2891cc85f552"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shapes:\n",
            "Padded inputs shape: torch.Size([18280, 512])\n",
            "Padded labels shape: torch.Size([18280, 512])\n",
            "Attention masks shape: torch.Size([18280, 512])\n",
            "\n",
            "Validation set shapes:\n",
            "Padded inputs shape: torch.Size([4570, 303])\n",
            "Padded labels shape: torch.Size([4570, 303])\n",
            "Attention masks shape: torch.Size([4570, 303])\n",
            "\n",
            "Test set shapes:\n",
            "Padded inputs shape: torch.Size([5712, 351])\n",
            "Padded labels shape: torch.Size([5712, 351])\n",
            "Attention masks shape: torch.Size([5712, 351])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tdqm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt8CZah5oZJ6",
        "outputId": "e42a9b6a-6b8b-4364-a069-1b07f943f938"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tdqm\n",
            "  Downloading tdqm-0.0.1.tar.gz (1.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tdqm) (4.67.1)\n",
            "Building wheels for collected packages: tdqm\n",
            "  Building wheel for tdqm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tdqm: filename=tdqm-0.0.1-py3-none-any.whl size=1322 sha256=bd0af6e03cf60adb15dd792714e2e6ff48c1833aa647845b1bf30ab959539c66\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/c7/30/e5935be2cfa6883be72462333edc414d8928f3c78eaabec38a\n",
            "Successfully built tdqm\n",
            "Installing collected packages: tdqm\n",
            "Successfully installed tdqm-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "EPOCHS = 3\n",
        "\n",
        "# Dataset class\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_masks, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_masks[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "# Validation function\n",
        "def evaluate(model, dataloader, device, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"  Validating\", leave=False):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits.view(-1, 3), labels.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=-1).view(-1)\n",
        "            true  = labels.view(-1)\n",
        "            mask  = (true != -100) & (true != 0)\n",
        "\n",
        "            all_preds.extend(preds[mask].cpu().numpy())\n",
        "            all_labels.extend(true[mask].cpu().numpy())\n",
        "\n",
        "    # compute B/I macro metrics\n",
        "    filtered_preds  = [p for p,t in zip(all_preds, all_labels) if t in [1,2]]\n",
        "    filtered_labels = [t for t in all_labels   if t in [1,2]]\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        filtered_labels, filtered_preds, labels=[1,2], average=\"macro\"\n",
        "    )\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss, precision, recall, f1\n",
        "\n",
        "# Model class\n",
        "class BioBERT_BiGRU_NER(nn.Module):\n",
        "    def __init__(self, bert_model_name, hidden_dim, num_labels=3, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
        "        self.gru  = nn.GRU(input_size=self.bert.config.hidden_size,\n",
        "                           hidden_size=hidden_dim,\n",
        "                           batch_first=True,\n",
        "                           bidirectional=True)\n",
        "        self.dropout    = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(hidden_dim * 2, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = outputs.last_hidden_state\n",
        "        gru_output, _ = self.gru(embeddings)\n",
        "        dropped = self.dropout(gru_output)\n",
        "        return self.classifier(dropped)\n",
        "\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    \"learning_rate\": [5e-5, 2e-5],\n",
        "    \"hidden_dim\":    [64, 128],\n",
        "    \"dropout\":       [0.1, 0.3],\n",
        "}\n",
        "\n",
        "# generate all combinations\n",
        "all_configs = list(itertools.product(\n",
        "    param_grid[\"learning_rate\"],\n",
        "    param_grid[\"hidden_dim\"],\n",
        "    param_grid[\"dropout\"],\n",
        "))\n",
        "# Create dataset objects\n",
        "train_dataset = NERDataset(train_padded_inputs, train_attention_masks, train_padded_labels)\n",
        "val_dataset   = NERDataset(val_padded_inputs, val_attention_masks, val_padded_labels)\n",
        "test_dataset  = NERDataset(test_padded_inputs, test_attention_masks, test_padded_labels)\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader   = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "test_dataloader  = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiaCIo_cKW9A",
        "outputId": "c8d0fb7a-080a-47f3-8c12-bec424177db7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_f1 = 0.0\n",
        "best_config = None\n",
        "\n",
        "# Grid search for training all configurations\n",
        "for lr, hid_dim, do_rate in all_configs:\n",
        "    print(f\"\\n>>> Config: lr={lr}, hidden_dim={hid_dim}, dropout={do_rate}\")\n",
        "\n",
        "    # init model, criterion, optimizer\n",
        "    model = BioBERT_BiGRU_NER(\"dmis-lab/biobert-base-cased-v1.1\",\n",
        "                              hidden_dim=hid_dim,\n",
        "                              dropout_rate=do_rate).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    # train + validate\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        # training pass\n",
        "        progress = tqdm(train_dataloader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False)\n",
        "        for batch in progress:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            mask      = batch['attention_mask'].to(device)\n",
        "            labels    = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(input_ids, mask)\n",
        "            loss   = criterion(logits.view(-1, 3), labels.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            progress.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_dataloader)\n",
        "        val_loss, precision, recall, f1 = evaluate(model, val_dataloader, device, criterion)\n",
        "\n",
        "        print(f\"  Epoch {epoch} → Train Loss: {avg_train_loss:.4f}  │  Val Loss: {val_loss:.4f}  │  F1(B/I): {f1:.4f}\")\n",
        "\n",
        "    # if this config is best so far, save model\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_config = (lr, hid_dim, do_rate)\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(f\"  >>> New best! Saved with F1={f1:.4f}\")\n",
        "\n",
        "print(f\"\\n=== Best config: lr={best_config[0]}, hidden_dim={best_config[1]}, dropout={best_config[2]} with F1={best_f1:.4f} ===\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI4EuNq_FmZ0",
        "outputId": "14c0fe4c-73ff-49ca-b62b-dd044eff7316"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "\n",
            ">>> Config: lr=5e-05, hidden_dim=64, dropout=0.1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 1 → Train Loss: 0.1490  │  Val Loss: 0.1002  │  F1(B/I): 0.0822\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 2 → Train Loss: 0.0966  │  Val Loss: 0.0800  │  F1(B/I): 0.3619\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 3 → Train Loss: 0.0840  │  Val Loss: 0.0715  │  F1(B/I): 0.4667\n",
            "  >>> New best! Saved with F1=0.4667\n",
            "\n",
            ">>> Config: lr=5e-05, hidden_dim=64, dropout=0.3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 1 → Train Loss: 0.1581  │  Val Loss: 0.1024  │  F1(B/I): 0.0846\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 2 → Train Loss: 0.1004  │  Val Loss: 0.0818  │  F1(B/I): 0.3462\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 3 → Train Loss: 0.0881  │  Val Loss: 0.0733  │  F1(B/I): 0.4397\n",
            "\n",
            ">>> Config: lr=5e-05, hidden_dim=128, dropout=0.1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 1 → Train Loss: 0.1315  │  Val Loss: 0.0873  │  F1(B/I): 0.2691\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 2 → Train Loss: 0.0864  │  Val Loss: 0.0722  │  F1(B/I): 0.4868\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 3 → Train Loss: 0.0758  │  Val Loss: 0.0644  │  F1(B/I): 0.5693\n",
            "  >>> New best! Saved with F1=0.5693\n",
            "\n",
            ">>> Config: lr=5e-05, hidden_dim=128, dropout=0.3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 1 → Train Loss: 0.1383  │  Val Loss: 0.0897  │  F1(B/I): 0.2150\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 2 → Train Loss: 0.0895  │  Val Loss: 0.0759  │  F1(B/I): 0.5392\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 3 → Train Loss: 0.0783  │  Val Loss: 0.0663  │  F1(B/I): 0.5393\n",
            "\n",
            ">>> Config: lr=2e-05, hidden_dim=64, dropout=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 → Train Loss: 0.2198  │  Val Loss: 0.1356  │  F1(B/I): 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3:  55%|█████▌    | 1266/2285 [05:06<04:08,  4.11it/s, loss=0.0937]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Saved"
      ],
      "metadata": {
        "id": "KZaAhTwWv1nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh \"best_model_config_5_128_.pt\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z-8jVm7Ltj-",
        "outputId": "45de418d-cc36-47b1-d301-bdd64185499f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 382M Apr 22 01:44 best_model_config_5_128_.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# manually set best_config\n",
        "lr = 5e-5\n",
        "hid_dim = 128\n",
        "do_rate = 0.1\n",
        "best_config = (lr, hid_dim, do_rate)\n",
        "model = BioBERT_BiGRU_NER(\n",
        "    bert_model_name=\"dmis-lab/biobert-base-cased-v1.1\",\n",
        "    hidden_dim=best_config[1],\n",
        "    dropout_rate=best_config[2]\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"biobert_biGRU_ner_model_trained.pth\", weights_only=False, map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "\n",
        "# Extract and save embeddings for a chosen split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Choose split: train_dataset, val_dataset or test_dataset\n",
        "dataset = val_dataset\n",
        "loader  = DataLoader(dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "all_embs, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(loader, desc=\"Extracting embeddings\"):\n",
        "        input_ids      = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels         = batch[\"labels\"]\n",
        "\n",
        "        # Only get the BioBERT embeddings (before GRU/classifier)\n",
        "        bert_out   = model.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embs       = bert_out.last_hidden_state.cpu()  # (B, seq_len, hidden_size)\n",
        "\n",
        "        all_embs.append(embs)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "# Concatenate and save\n",
        "emb_tensor = torch.cat(all_embs,  dim=0)  # (N, seq_len, hidden_size)\n",
        "lbl_tensor = torch.cat(all_labels, dim=0)  # (N, seq_len)\n",
        "\n",
        "torch.save(emb_tensor, \"val_embeddings.pt\")\n",
        "torch.save(lbl_tensor, \"val_labels.pt\")\n",
        "print(\"Saved:\", emb_tensor.shape, lbl_tensor.shape)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"val_embeddings.pt\")\n",
        "files.download(\"val_labels.pt\")\n",
        "files.download(\"best_model.pt\")\n"
      ],
      "metadata": {
        "id": "8qK1nhJ6qVzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa26d49d-ed77-4343-c326-0b52c31f6477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings:   1%|          | 5/572 [00:52<1:40:40, 10.65s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IGNORE ALL CELLS BELOW THIS"
      ],
      "metadata": {
        "id": "qJukTnDHOMEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Extract embeddings from BioBERT ===\n",
        "def extract_embeddings_and_labels(dataloader):\n",
        "    all_embeddings = []\n",
        "    all_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels']\n",
        "\n",
        "            outputs = model.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            embeddings = outputs.last_hidden_state.cpu()\n",
        "            all_embeddings.extend(embeddings)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    return all_embeddings, all_labels\n",
        "\n",
        "train_embeddings, train_labels = extract_embeddings_and_labels(train_dataloader)\n",
        "val_embeddings, val_labels = extract_embeddings_and_labels(val_dataloader)\n",
        "test_embeddings, test_labels = extract_embeddings_and_labels(test_dataloader)\n",
        "\n",
        "# === Define tag2idx and idx2tag ===\n",
        "tag2idx = {\"O\": 0, \"B\": 1, \"I\": 2}\n",
        "idx2tag = {v: k for k, v in tag2idx.items()}\n",
        "\n",
        "# === Save embeddings and labels ===\n",
        "import os, json\n",
        "os.makedirs(\"embeddings\", exist_ok=True)\n",
        "torch.save(train_embeddings, \"embeddings/train_embeddings.pt\")\n",
        "torch.save(val_embeddings, \"embeddings/val_embeddings.pt\")\n",
        "torch.save(test_embeddings, \"embeddings/test_embeddings.pt\")\n",
        "\n",
        "torch.save(train_labels, \"embeddings/train_labels.pt\")\n",
        "torch.save(val_labels, \"embeddings/val_labels.pt\")\n",
        "torch.save(test_labels, \"embeddings/test_labels.pt\")\n",
        "\n",
        "with open(\"embeddings/tag2idx.json\", \"w\") as f:\n",
        "    json.dump(tag2idx, f)\n",
        "with open(\"embeddings/idx2tag.json\", \"w\") as f:\n",
        "    json.dump(idx2tag, f)\n",
        "\n",
        "print(\"✅ Embeddings and labels saved.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9OxuVpMTVnUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/best_model.pt')"
      ],
      "metadata": {
        "id": "0kAlWaGLVwAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model (architecture + trained weights)\n",
        "torch.save(model.state_dict(), 'biobert_biGRU_ner_model_trained_1.pth')\n",
        "# # Save model and optimizer state (for resuming training)\n",
        "# torch.save({\n",
        "#     'epoch': epoch,\n",
        "#     'model_state_dict': model.state_dict(),\n",
        "#     'optimizer_state_dict': optimizer.state_dict(),\n",
        "#     'loss': loss.item(),\n",
        "# }, 'checkpoint.pth')\n"
      ],
      "metadata": {
        "id": "3L2iwkMXvxIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/biobert_biGRU_ner_model_trained.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zPJu0Ujs1HwE",
        "outputId": "768e96cd-0000-49f1-af27-4ed7a8b0fb22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4aeb38c8-54f1-4295-bf09-a115e5c06f1c\", \"biobert_biGRU_ner_model_trained.pth\", 436090606)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}